# pip install beautifulsoup4
# pip install requests


# Переходим в редактор кода и импортируем наши библиотеки:
from bs4 import BeautifulSoup
import requests

# Для начала сохраним наш URL в переменную:
url = 'http://mignews.com/mobile'

# Теперь отправим GET()-запрос на сайт и сохраним полученное в переменную 'page':
page = requests.get(url)

# Проверим подключение:
print(page.status_code)
# Код вернул нам статус код '200', значит это, что мы успешно подключены и все в полном порядке.

# Теперь создадим два списка (позже я объясню для чего они нужны):
filteredNews = []
allNews = []

# Самое время воспользоваться BeautifulSoup4 и скормить ему наш page, указав в кавычках как он нам поможет 'html.parcer':
soup = BeautifulSoup(page.text, "html.parser")

# Если попросить его показать, что он там сохранил:
print(soup)
# Нам вылезет весь html-код нашей страницы.

# Теперь воспользуемся функцией поиска в BeautifulSoup4:
allNews = soup.findAll('a', class_='lenta')
# Давайте разберём поподробнее, что мы тут написали.
# В ранее созданный список 'news' (к которому я обещал вернуться), сохраняем все с тэгом 'а' и классом 'news'. Если попросим вывести в консоль все, что он нашел, он покажет нам все новости, что были на странице.

# Продолжим:
for data in allNews:
    if data.find('span', class_='time2 time3') is not None:
        filteredNews.append(data.text)
# Тут мы в цикле for перебираем весь наш список новостей. Если в новости мы находим тэг 'span' и класc 'time2 time3', то сохраняем текст из этой новости в новый список 'filteredNews'.
# Обратите внимание, что мы используем '.text', чтобы переформатировать строки в нашем списке из 'bs4.element.ResultSet', который использует BeautifulSoup для своих поисков, в обычный текст.
# Однажды я застрял на этой проблеме надолго в силу недопонимания работы форматов данных и неумения использовать debug, будьте осторожны. Таким образом теперь мы можем сохранять эти данные в новый список и использовать все методы списков, ведь теперь это обычный текст и, в общем, делать с ним, что нам захочется.

# Выведем наши данные:
for data in filteredNews:
    print(data)
# Мы получаем время публикации и лишь интересные новости.



# https://habr.com/ru/post/544828/ Облегчаем себе жизнь с помощью BeautifulSoup4