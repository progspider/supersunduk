https://otus.ru/nest/post/703/

#Парсинг страниц на Python. Parser на Python

Рано или поздно любой Python-программист сталкивается с задачей скопировать какой-нибудь материал с сайта. Так как страниц на нём достаточно много, терять время на ручное копирование — не самый лучший выход. К тому же, языки программирования затем и нужны, чтобы избавлять нас от рутинной работы, автоматизируя решение различных задач. Если же говорить о работе с HTML, то в Python есть отличные библиотеки для этого. Они позволяет парсить как сайты, так и обычные HTML-документы. 

#Парсер — что это вообще такое?

Если вы ещё не сталкивались с этим понятием, то давайте поговорим о нём подробнее. Итак, парсером называют скрипт, который осуществляет синтаксический анализ данных с последующих их отбором и группировкой в БД либо электронную таблицу. Эта программа выполняет сопоставление линейной последовательности слов с учётом правил языка. 

Алгоритм работы парсера:
1. Получение доступа к сети и API веб-ресурса, его скачивание. 
2. Извлечение, исследование и обработка скачанных данных.
3. Экспорт полученной информации.

По сути, парсинг может проводиться с применением разных языков программирования, но проще всего показать его именно на Python, благодаря простому синтаксису.

Что касается назначения парсинга, то он используется в разных целях, например:
— сбор информации для своего сайта;
— индексация веб-страниц;
— получение данных, не являющихся интеллектуальной собственностью и т. д. 

Но чтобы парсер полноценно выполнил поставленные задачи, нужно подготовить среду, о чём и поговорим.

#Готовим к работе скрипт парсинга на Python

Подготовка включает в себя 2 этапа: сначала мы должны освежить свои знания в некоторых областях, а потом можно приступить и к подготовке библиотек.

Итак, для успешного парсинга вам потребуются:
1. Знание PHP, HTML, CSS, JavaScript. Они нужны для первичного анализа и понимания кода страницы, с которой и будем осуществлять парсинг. Не стоит думать, что всё так просто, ведь порой и опытный специалист не может разобраться в структуре сайта, написанного на HTML.
2. Знание и понимание, как применять библиотеки HTML-парсинга на Python, а также регулярные выражения. Это поможет разобраться с проблемами, связанными с невалидным кодом.
3. Основы объектно-ориентированного программирования (желательно).
4. Знания баз данных, например, MySQL. Это необходимо для обработки выходных данных.

Вышеперечисленное — базис, владея которым HTML-парсинг не вызовет у вас затруднений. Также было бы неплохо уметь работать с иерархическими структурами, XML и JSON.

Переходим ко второй части — библиотекам. Вот основные: 
— LXML. Пакет, имеющий поддержку XLST и XPath. Отличается богатым функционалом по обработке разных API;
— GRAB. Очень распространённый инструмент, работает с DOM, может выполнять автозаполнение форм, обрабатывать перенаправление с сайтов;
— Beautiful Soup. Прекрасно справляется со структурным разбором сайта, а также с обработкой невалидного кода HTML.

#Устанавливаем библиотеку Beautiful Soup (Linux)

Прекрасным преимуществом этой библиотеки является наличие персонального алгоритма структурирования HTML-кода. А это уже позволяет сэкономить разработчику время, что не может не радовать. Итак, устанавливаем:

	$ apt-get install python-bs4
	$ apt-get install python-lxml
	$ apt-get install python-html5lib

Установив нужные модули, можем парсить сайт. В результате мы получим его структурированный код:

	# -*- coding: utf-8 -*-
	from bs4 import BeautifulSoup
	from urllib2 import urlopen
	html_doc = urlopen('http://otus.ru').read()
	soup = BeautifulSoup(html_doc)
	print soup

Чтобы выполнить поиск по ссылкам:

	for link in soup.find_all('a'):
		print link.get('href')
	# Содержимое ссылок
	for link in soup.find_all('a'):
		print link.contents[0]

А вот так работает парсер DIV-блоков:

	# Содержимое из <div class="content"> ... </div>
	print soup.find('div', 'content')
	# Блок: <div id="top_menu"> ... </div>
	print soup.find('div', id='top_menu')

Если хотим получить ссылки на изображения:

	for img in soup.find_all('img'):
		print img.get('src')

Как видим, ничего сложного нет.