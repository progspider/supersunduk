ИСТОЧНИК: https://remontka.pro/stable-diffusion-install-use/

Установка и использование Stable Diffusion для генерации изображений

Всё моё свободное время в последние четыре дня было потрачено на одну задачу — составление запросов для нейросети Stable Diffusion, нейросети для создания изображений по текстовому описанию. Все изображения для статьи (кроме скриншотов) были созданы лично в этой нейросети, совершенно не художником.

В этой инструкции подробно о том, как установить Stable Diffusion на ваш компьютер или ноутбук, о возможности попробовать нейросеть в работе без установки и некоторые дополнительные детали, которые могут оказаться полезными, если вы решите нырнуть в это также, как и я.

Установка Stable Diffusion

Нейросеть Stable Diffusion отличается от таких аналогов как DALL-E 2 или Midjourney открытым исходным кодом: то есть, при наличии соответствующего оборудования, вы можете совершенно бесплатно установить необходимое ПО на свой компьютер и использовать для создания изображений по текстовому запросу (в обсуждениях часто используют кальку с английского «промпт»).

Официальное ПО Stable Diffusion не имеет удобного графического интерфейса, за исключением доступного на официальном сайте https://beta.dreamstudio.ai/, с которого и рекомендую начать эксперименты и посмотреть, нужно ли вам это: после регистрации у вас будет 200 бесплатных генераций с параметрами по умолчанию (регистрироваться можно и больше раз с разными адресами электронной почты).

При установке официального софта на компьютере все действия придётся выполнять в командной строке. Кроме того, вы мало что сможете сгенерировать с видеокартой, имеющей 6 Гб памяти или менее.

Однако, благодаря открытому исходному коду, почти сразу после релиза Stable Diffusion появились альтернативные варианты ПО («форки»), оптимизирующие запуск на более слабом оборудовании (4 Гб VRAM, есть даже варианты, работающие на CPU, но очень медленно), предоставляющие удобный доступ к настройкам и упрощающие использование нейросети.

С одного из таких альтернативных вариантов, который я нашел наиболее удачным, и начнем установку. Если же вам требуется описание процесса установки официального варианта, его вы также сможете найти далее в статье.

Установка Stable Diffusion WebUI от Automatic

Внимание: с момент написания инструкции процесс установки менялся и уточнить необходимые шаги лучше на официальном GitHub проекта: https://github.com/AUTOMATIC1111/stable-diffusion-webui

Сначала о том, что нам потребуется: достаточно мощный компьютер или ноутбук, видеокарта NVIDIA GeForce, не менее 4 Гб видеопамяти. Все устанавливаемые компоненты займут около 10 Гб на жестком диске или SSD. Если всё это в наличии, можно приступать:

 1. Установите Python 3.10.6 (разработчик указывает именно эту версию) с официального сайта https://www.python.org/downloads/windows/. При установке отметьте пункт «Добавить Python в переменную PATH».
 
 2. Установите Git с официального сайта https://git-scm.com/download/win. Если вам не ясны параметры при установке, их можно оставить в рекомендуемых по умолчанию значениях.
 
 3. Зайдите на страницу Automatic1111 на GitHub https://github.com/AUTOMATIC1111/stable-diffusion-webui, нажмите по стрелке справа от кнопки «Code» вверху справа и загрузите ZIP-архив со Stable Diffusion WebUI. Распакуйте в удобное расположение, но так, чтобы путь не содержал пробелов или кириллических символов (это может вызвать проблемы).
 
 4. Скачайте обученную модель Stable Diffusion последней версии с официального источника https://huggingface.co/CompVis/stable-diffusion-v-1-4-original (потребуется регистрация) или из этого (https://drive.yerf.org/wl/?id=EBfTrmcCCUAGaQBXVIj5lJmEhjoP1tgl) хранилища.
 
 5. Переименуйте скачанный файл в model.ckpt и переместите его в папку, куда были распакованы файлы на 3-м шаге (в ту же папку, где находится файл webui.bat).
 
 6. Запустите файл webui-user.bat (не от имени администратора, простой запуск двойным кликом) и дождитесь, когда скрипт автоматически скачает и установит недостающие компоненты. Учитывайте: строка прогресса не отображается, поэтому при загрузке объемных компонентов (Torch и CUDA) может показаться, что процесс завис.
 
 7. По завершении установки вы увидите сообщение: Running on local URL: http://127.0.0.1:7860/ 
 перейдите по указанному адресу (не закрывайте окно консоли, это прервет работу Stable Diffusion WebUI) в любом браузере и начните использование.

 8. Если ваша видеокарта имеет 6 Гб видеопамяти или меньше, при попытке сгенерировать изображение даже в выставленном по умолчанию расширении 512×512 вы можете получить сообщение о недостатке VRAM (видеопамяти). В этом случае, закройте окно консоли (или прервите выполнение, нажав Ctrl+C в окне консоли), откройте файл webui-user.bat с помощью текстового редактора и измените строку с параметрами запуска на: set COMMANDLINE_ARGS=--medvram 
 Затем снова запустите веб-интерфейс файлом webui-user.bat
 
 9. Дополнительные возможности настройки Stable Diffusion WebUI и параметры запуска можно найти на официальной странице разработчика.

Установка официальной версии Stable Diffusion

При установке официальной версии Stable Diffusion все необходимые компоненты почти те же самые, но их потребуется устанавливать вручную. Требования те же самые, за исключением необходимости использования видеокарты с не менее чем 6 Гб VRAM.

 1. Скачайте и установите Git https://git-scm.com/download/win используйте рекомендуемые параметры (оставьте возможность использования Git в командной строке и сторонних программах).
 
 2. Установите Miniconda3 с официального сайта https://docs.conda.io/en/latest/miniconda.html, при установке выберите опцию «Установить для всех пользователей).
 
 3. Скачайте архив Stable Diffusion с официального источника https://github.com/CompVis/stable-diffusion (нажать по кнопке «Code», затем выбрать пункт «Download ZIP»).
 
 4. Скачайте модель Stable Diffusion последней версии с https://huggingface.co/CompVis/stable-diffusion-v-1-4-original (потребуется регистрация) или: из этого хранилища (без регистрации), переименуйте файл в model.ckpt
 
 5. Запустите консоль Miniconda3 (Anaconda Prompt), для этого можно использовать поиск в панели задач Windows 11 и Windows
 
 6. В открывшейся консоли используйте команды для создания папки (в нашем варианте — на диске C) для файлов Stable Diffusion
     cd C:/
     mkdir stable-diffusion
     cd stable-diffusion

 Не закрывайте окно консоли.

 7. Откройте скачанный на 3-м шаге архив и скопируйте папку stable-diffusion-main (саму папку, а не файлы в ней) в C:\stable-diffusion\
 
 8. По порядку используйте следующие команды в консоли Miniconda3
     cd C:\stable-diffusion\stable-diffusion-main
     conda env create -f environment.yaml
     conda activate ldm
     mkdir models\ldm\stable-diffusion-v1
	 
 Процесс займет продолжительное время, так как из сети будут скачиваться дополнительные компоненты.

 9. Переместите файл model.ckpt в папку C:\stable-diffusion\stable-diffusion-main\models\ldm\stable-diffusion-v1
 
 10. Готово. Теперь мы можем запустить Stable Diffusion, введя команду: conda activate ldm
 В дальнейшем запуск будет всегда производиться именно с помощью этой команды.

 11. Генерация изображений выполняется здесь же в консоли с помощью передачи параметров. Например, вы можете ввести:
 
  python scripts/txt2img.py --prompt "concept robot, colorful, cinematic" --plms --n_iter 5 --n_samples 1
  
  Команда создаст набор из 5 изображений с разрешением 512×512 по запросу «concept robot, colorful, cinematic», которые будут помещены в папку: C:\stable-diffusion\stable-diffusion-main\outputs\txt2img-samples\samples

Чтобы увидеть информацию по доступным параметрам командной строки используйте команду: python scripts/txt2img.py --help

Использование Stable Diffusion WebUI

После запуска webui-user.bat и перехода в браузере на адрес 127.0.0.1:7860 перед вами будет веб-интерфейс, доступный локально на вашем компьютере (для работы Интернет не требуется), первая вкладка которого — txt2img, где и происходит всё самое интересное. Экспериментировать можно начать сразу же: просто введите текст на английском в поле сверху и нажмите кнопку «Generate», чтобы получить готовую картинку с параметрами по умолчанию.

Если поднести указатель мыши к названию доступных параметров, большинство из них имеют описания на английском. Среди основных:

 ● Sampling Method — алгоритм создания изображения. Влияет на результат, скорость, требуемую видеопамять.
 ● Sampling Steps — количество шагов, в течение которых нейросеть «приводит» результат к желаемому. Влияет на время генерации. Больше — не всегда лучше: нужный результат может получиться за 30-50 шагов, а дальнейшая работа может не добавить деталей, а исказить результат (но бывает и иначе). Если то, что получилось, вам понравилось, можно использовать тот же Seed для генерации изображения по этому же запросу, но с другим количеством шагов и оценить результат.
 ● Batch count — количество наборов создаваемых изображений.
 ● Batch size — количество изображений в наборе (влияет на требуемую память).
 ● CGF Scale — «свобода» обработчика изображения, влияет на то, насколько точно результат будет соответствовать описанию. При более низких значениях получаем большее разнообразие.
 ● Height и Width — ширина и высота изображения, очень сильно влияет на требования к памяти.
 ● Seed — «зерно». По умолчанию равно -1, при этом значении оно будет задано случайно при каждом очередном нажатии кнопки «Generate». Если с определенным Seed вы получили интересный результат, можете скопировать его в это поле, чтобы продолжить эксперименты над понравившимся изображением, изменяя параметры.

По умолчанию изображения сохраняются во вложенных папках в папке outputs в расположении, куда вы установили Stable Diffusion WebUI, но при желании автоматическое сохранение можно отключить на вкладке «Settings», здесь же можно настроить и другие параметры.

Вкладка img2img позволяет модифицировать имеющееся изображение в соответствии с текстовым описанием.

На вкладке Extras собраны дополнительные инструменты. Основное — увеличение разрешения изображения с использованием нейросети.
